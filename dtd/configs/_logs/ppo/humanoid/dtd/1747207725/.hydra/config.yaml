run_name: _
run_time: 1747207725
env:
  name: humanoid
  backend: generalized
  num_envs: 64
  num_envs_for_eval: 32
  noise_lvl: 0.0
  action_size: _
  observation_size: _
  dt: _
load: false
save: false
reward_curves: false
seed: 0
algorithm:
  agent_class: ppo
  TD: dtd
  seed: 42
  total_timesteps: 2500000
  num_updates: _
  num_minibatches: _
  minibatch_size: 256
  num_env_steps_per_update: 16
  num_env_steps_for_eval: 1000
  num_epochs_per_update: 10
  anneal_lr: true
  max_grad_norm: 0.5
  model_kwargs:
    activation: relu
    learning_rate: 0.001075153905643759
    gamma: 0.99
    gae_lambda: 0.8880142695907592
    clip_range: 0.7125623349891503
    normalize_advantage: 0.0
    ent_coef: 0.0017430891372372192
    vf_coef: 0.0535497409069704
    mix_ratio: 0.33159218906798826
search_space:
  hyperparameters:
    algorithm.num_env_steps_per_update:
      type: categorical
      choices:
      - 8
      - 16
      - 32
    algorithm.minibatch_size:
      type: categorical
      choices:
      - 256
      - 512
    algorithm.num_epochs_per_update:
      type: uniform_int
      lower: 5
      upper: 20
      log: false
    algorithm.model_kwargs.learning_rate:
      type: uniform_float
      lower: 1.0e-06
      upper: 0.005
      log: true
    algorithm.model_kwargs.normalize_advantage:
      type: categorical
      choices:
      - 0.0
      - 1.0
    algorithm.model_kwargs.gae_lambda:
      type: uniform_float
      lower: 0.8
      upper: 0.9999
      log: false
    algorithm.model_kwargs.clip_range:
      type: uniform_float
      lower: 0.0
      upper: 0.9
      log: false
    algorithm.model_kwargs.ent_coef:
      type: uniform_float
      lower: 0.0
      upper: 0.3
      log: false
    algorithm.model_kwargs.vf_coef:
      type: uniform_float
      lower: 0.0
      upper: 1.0
      log: false
    algorithm.model_kwargs.mix_ratio:
      type: uniform_float
      lower: 0.0
      upper: 1.0
      log: false
